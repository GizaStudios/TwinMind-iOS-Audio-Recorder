//
//  Models.swift
//  TwinMind
//
//  Created by Devin Morgan on 7/1/25.
//

import Foundation
import SwiftData

// MARK: - Enumerations

/// Where a transcription came from—useful for analytics and fallback logic.
enum TranscriptionSource: String, Codable {
    case whisperAPI
    case appleLocal
    case localWhisper
}

/// Current processing state for a segment's transcription.
enum TranscriptionStatus: String, Codable {
    case notStarted
    case inProgress
    case completed
    case failed
}

// MARK: - RecordingSession

/// Represents a user‑initiated recording session (one tap on "Record").
@Model
class RecordingSession {
    // Primary key
    @Attribute(.unique) var id: UUID

    // User‑visible title or autogenerated timestamp string
    var title: String

    // Session start time
    var createdAt: Date

    // Whole‑session length in seconds (updated when recording stops)
    var duration: TimeInterval

    // Absolute path to the combined/raw audio file on disk
    var audioFilePath: String

    // Audio quality metadata captured at record time
    var sampleRate: Double
    var bitDepth: Int
    var format: String // e.g. "m4a", "wav"
    
    // Generated session summary/notes from AI processing
    var notes: String?
    
    // Track summary generation state
    var summaryGenerationFailed: Bool = false

    // Relationship → constituent 30‑s segments
    var segments: [AudioSegment] = []

    init(title: String,
         createdAt: Date = .now,
         duration: TimeInterval = 0,
         audioFilePath: String,
         sampleRate: Double,
         bitDepth: Int,
         format: String,
         notes: String? = nil,
         summaryGenerationFailed: Bool = false) {
        self.id = UUID()
        self.title = title
        self.createdAt = createdAt
        self.duration = duration
        self.audioFilePath = audioFilePath
        self.sampleRate = sampleRate
        self.bitDepth = bitDepth
        self.format = format
        self.notes = notes
        self.summaryGenerationFailed = summaryGenerationFailed
    }
}

// MARK: - AudioSegment

/// A slice of the recording (default 30 s) that is independently transcribed.
@Model
class AudioSegment {
    @Attribute(.unique) var id: UUID

    // Offset relative to RecordingSession start
    var startTime: TimeInterval
    var endTime: TimeInterval

    // Creation timestamp for indexing & analytics
    var createdAt: Date?

    // Path to the on-disk audio slice
    var segmentFilePath: String

    // Transcription pipeline state
    var status: TranscriptionStatus
    var retryCount: Int
    /// Real-time transcription progress 0.0 – 1.0
    var progress: Double?
    var lastError: String?

    // Relationships
    var transcription: Transcription?
    var session: RecordingSession?

    init(startTime: TimeInterval,
         endTime: TimeInterval,
         segmentFilePath: String,
         status: TranscriptionStatus = .notStarted,
         retryCount: Int = 0,
         lastError: String? = nil,
         createdAt: Date? = .now,
         progress: Double? = 0.0) {
        self.id = UUID()
        self.startTime = startTime
        self.endTime = endTime
        self.segmentFilePath = segmentFilePath
        self.status = status
        self.retryCount = retryCount
        self.lastError = lastError
        self.createdAt = createdAt
        self.progress = progress
    }
}

// MARK: - Transcription

/// Holds the text produced for an AudioSegment plus metadata.
@Model
class Transcription {
    @Attribute(.unique) var id: UUID

    var text: String
    var confidence: Double // 0.0 – 1.0
    var language: String?  // ISO 639‑1 code if available
    var createdAt: Date
    var source: TranscriptionSource

    // Back‑reference
    var segment: AudioSegment?

    init(text: String,
         confidence: Double,
         language: String? = nil,
         createdAt: Date = .now,
         source: TranscriptionSource) {
        self.id = UUID()
        self.text = text
        self.confidence = confidence
        self.language = language
        self.createdAt = createdAt
        self.source = source
    }
}

// MARK: - Computed helpers
extension RecordingSession {
    /// Aggregate progress of all segments (0.0 – 1.0)
    var progress: Double {
        guard !segments.isEmpty else { return 0 }
        let total = segments.reduce(0.0) { $0 + ($1.progress ?? 0.0) }
        return total / Double(segments.count)
    }
} 